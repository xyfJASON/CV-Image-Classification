seed: 1234                    # random seed

data:
  name: CIFAR-10              # name of the dataset
  dataroot: /data/CIFAR-10/   # path to the dataset
  img_size: 32                # size of the image
  n_classes: 10               # number of classes in the dataset

dataloader:
  num_workers: 4              # number of workers
  pin_memory: true            # pin memory
  prefetch_factor: 2          # prefetch factor
  micro_batch: 0              # in case the gpu memory is too small, split a batch into micro batches
                              # the gradients of micro batches will be aggregated for an update step

model:
  name: shufflenet_1_0x_g8    # name of the model
  first_block: cifar10        # 'cifar10' or 'imagenet'

train:
  train_steps: 64000          # training duration, one step means one gradient update
  batch_size: 256             # total batch size
  resume: ~                   # options: path to checkpoint, 'best', 'latest', none
  print_freq: 200             # frequency of printing status, in steps
  save_freq: 5000             # frequency of saving checkpoints, in steps
  eval_freq: 1000             # frequency of evaluating the model, in steps

  optim:
    type: SGD                 # type of the optimizer
    lr: 0.1                   # learning rate
    weight_decay: 0.0005      # weight decay
    momentum: 0.9             # momentum, for sgd

  sched:
    type: CosineAnnealingLR   # type of the scheduler
    t_max: 64000              # argument of CosineAnnealingLR
    eta_min: 0.001            # argument of CosineAnnealingLR
    warmup_steps: 0           # warmup steps
    warmup_factor: 0.01       # warmup factor
